<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI-Assisted Trader Mini-Series on Steven Lasch Portfolio</title><link>https://slasch-portfolio.github.io/posts/ai-trader/</link><description>Recent content in AI-Assisted Trader Mini-Series on Steven Lasch Portfolio</description><generator>Hugo -- gohugo.io</generator><language>bn</language><lastBuildDate>Sat, 30 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://slasch-portfolio.github.io/posts/ai-trader/index.xml" rel="self" type="application/rss+xml"/><item><title>AI-Assisted Trader (Part 3)</title><link>https://slasch-portfolio.github.io/posts/ai-trader/part-3/</link><pubDate>Sat, 30 Nov 2024 00:00:00 +0000</pubDate><guid>https://slasch-portfolio.github.io/posts/ai-trader/part-3/</guid><description>&lt;h2 id="tldr"&gt;TLDR&lt;/h2&gt;
&lt;p&gt;This article is the third and final installment of creating an AI-Based trading strategy using reinforcement learning. In the last article, the learner proved to make sensible trades during the testing phase, assuming no transaction costs. In this article, we will explore the effects of one type of transaction cost, &lt;strong&gt;market impact&lt;/strong&gt;, and how this number affects trade volume and returns.&lt;/p&gt;
&lt;h2 id="what-is-market-impact"&gt;What is market impact?&lt;/h2&gt;
&lt;p&gt;Market impact measures how the actions of a buyer or seller affect the price of an asset in the market. It is one type of a broader category called transaction costs. Each transaction has a small effect on the market value of an asset. However, when scaled up to trading with millions of dollars, these tiny fractions magnify to large sums.&lt;/p&gt;</description></item><item><title>AI-Assisted Trader (Part 2)</title><link>https://slasch-portfolio.github.io/posts/ai-trader/part-2/</link><pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate><guid>https://slasch-portfolio.github.io/posts/ai-trader/part-2/</guid><description>&lt;h2 id="tldr"&gt;TLDR&lt;/h2&gt;
&lt;p&gt;This is Part 2 of my series on an AI-assisted stock trader. Refer to &lt;a href="https://steven-lasch.com/posts/ai-trader/part-1/" target="_blank" rel="noopener"&gt;Part 1&lt;/a&gt; to get more information on the requirements for a Q-Learner, though I will give a brief
introduction anyway. A Q-Learner is a type of reinforcement learning algorithm to find the optimal strategy based on its environment. It requires an &lt;strong&gt;action&lt;/strong&gt;, a &lt;strong&gt;state&lt;/strong&gt;, and some &lt;strong&gt;reward&lt;/strong&gt; for taking an action (reward can be positive to encourage an action, or negative to discourage an action).&lt;/p&gt;</description></item><item><title>AI-Assisted Trader - Introduction (Part 1)</title><link>https://slasch-portfolio.github.io/posts/ai-trader/part-1/</link><pubDate>Wed, 27 Nov 2024 00:00:00 +0000</pubDate><guid>https://slasch-portfolio.github.io/posts/ai-trader/part-1/</guid><description>&lt;h2 id="tldr"&gt;TLDR&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In this post, I will cover concepts in &lt;strong&gt;reinforcement learning (RL)&lt;/strong&gt;, specifically Q-Learning, applied to the context of maximizing returns in a simulated stock market environment.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Enjoy!ðŸ™‚&lt;/p&gt;
&lt;h2 id="q-learning"&gt;Q-Learning&lt;/h2&gt;
&lt;p&gt;As briefly described above, &lt;a href="https://en.wikipedia.org/wiki/Q-learning" target="blank"&gt;Q-Learning&lt;/a&gt; is an RL technique that learns the optimal strategy (called a &lt;strong&gt;policy&lt;/strong&gt; in RL) from three distinct elements: the &lt;strong&gt;action space&lt;/strong&gt;, the &lt;strong&gt;state space&lt;/strong&gt;, and a &lt;strong&gt;reward function&lt;/strong&gt;. Interestingly, the &amp;ldquo;Q&amp;rdquo; in Q-Learning comes from the act of focusing on the &lt;em&gt;quality&lt;/em&gt; of each action, and choosing the best action.&lt;/p&gt;</description></item></channel></rss>